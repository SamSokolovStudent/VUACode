{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-13T01:44:27.869565300Z",
     "start_time": "2023-11-13T01:44:27.769267500Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# from langchain.document_loaders import TextLoader\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "# from langchain.text_splitter import CharacterTextSplitter\n",
    "# from langchain.vectorstores import mongodb_atlas\n",
    "dotenv_path = r'C:\\Users\\Soko\\Documents\\GitHub\\VUACode\\.env'\n",
    "\n",
    "load_dotenv(dotenv_path)\n",
    "MONGODB_ATLAS_CLUSTER_URI = os.getenv('MONGODB_URI')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# initialize MongoDB python client\n",
    "client = MongoClient(MONGODB_ATLAS_CLUSTER_URI)\n",
    "DB_NAME = \"twinning_papers\"\n",
    "COLLECTION_NAME = \"papers\"\n",
    "ATLAS_VECTOR_SEARCH_INDEX_NAME = \"paperIndex\"\n",
    "\n",
    "MONGODB_COLLECTION = client[DB_NAME][COLLECTION_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load the PDF\n",
    "loader = PyPDFLoader(\"https://arxiv.org/pdf/2303.08774.pdf\")\n",
    "data = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "docs = text_splitter.split_documents(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T00:44:48.866050400Z",
     "start_time": "2023-11-13T00:44:43.084126500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='wherekandαare positive constants, and Pis a subset of problems in the dataset. We hypothesize\\nthat this relationship holds for all problems in this dataset. In practice, very low pass rates are difﬁcult\\nor impossible to estimate, so we restrict to problems Pand models Msuch that given some large\\nsample budget, every problem is solved at least once by every model.\\nWe registered predictions for GPT-4’s performance on HumanEval before training completed, using\\nonly information available prior to training. All but the 15 hardest HumanEval problems were split\\ninto 6 difﬁculty buckets based on the performance of smaller models. The results on the 3rdeasiest\\nbucket are shown in Figure 2, showing that the resulting predictions were very accurate for this\\nsubset of HumanEval problems where we can accurately estimate log(pass _rate) for several smaller\\nmodels. Predictions on the other ﬁve buckets performed almost as well, the main exception being' metadata={'source': 'C:\\\\Users\\\\Soko\\\\AppData\\\\Local\\\\Temp\\\\tmpzxx232hb\\\\tmp.pdf', 'page': 3}\n"
     ]
    }
   ],
   "source": [
    "print(docs[11])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T00:45:12.279761700Z",
     "start_time": "2023-11-13T00:45:12.254715500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance based on models trained with no more than 1/1,000th the compute of\n",
      "GPT-4.\n",
      "1 Introduction\n",
      "This technical report presents GPT-4, a large multimodal model capable of processing image and\n",
      "text inputs and producing text outputs. Such models are an important area of study as they have the\n",
      "potential to be used in a wide range of applications, such as dialogue systems, text summarization,\n",
      "and machine translation. As such, they have been the subject of substantial interest and progress in\n",
      "recent years [1–34].\n",
      "One of the main goals of developing such models is to improve their ability to understand and generate\n",
      "natural language text, particularly in more complex and nuanced scenarios. To test its capabilities\n",
      "in such scenarios, GPT-4 was evaluated on a variety of exams originally designed for humans. In\n",
      "these evaluations it performs quite well and often outscores the vast majority of human test takers.\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import MongoDBAtlasVectorSearch\n",
    "\n",
    "# insert the documents in MongoDB Atlas with their embedding\n",
    "vector_search = MongoDBAtlasVectorSearch.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=OpenAIEmbeddings(disallowed_special=()),\n",
    "    collection=MONGODB_COLLECTION,\n",
    "    index_name=ATLAS_VECTOR_SEARCH_INDEX_NAME,\n",
    ")\n",
    "\n",
    "# Perform a similarity search between the embedding of the query and the embeddings of the documents\n",
    "query = \"What were the compute requirements for training GPT 4\"\n",
    "results = vector_search.similarity_search(query)\n",
    "\n",
    "print(results[0].page_content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T22:37:34.549607800Z",
     "start_time": "2023-11-12T22:37:24.499659400Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
